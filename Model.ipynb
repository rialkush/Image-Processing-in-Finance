{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cTU8IEC5KT7Z"
   },
   "outputs": [],
   "source": [
    "seed_value= 0\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.set_random_seed(seed_value)\n",
    "\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain \n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AQbDuksfKwU0"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Data/Original/testing.csv\")  #test-set for financial evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-04-2018</td>\n",
       "      <td>893.000000</td>\n",
       "      <td>900.950012</td>\n",
       "      <td>886.500000</td>\n",
       "      <td>892.950012</td>\n",
       "      <td>879.384521</td>\n",
       "      <td>5712065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-04-2018</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>901.700012</td>\n",
       "      <td>885.250000</td>\n",
       "      <td>899.549988</td>\n",
       "      <td>885.884277</td>\n",
       "      <td>6364728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-04-2018</td>\n",
       "      <td>904.700012</td>\n",
       "      <td>911.799988</td>\n",
       "      <td>892.049988</td>\n",
       "      <td>894.900024</td>\n",
       "      <td>881.304932</td>\n",
       "      <td>6498407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-04-2018</td>\n",
       "      <td>905.099976</td>\n",
       "      <td>910.000000</td>\n",
       "      <td>903.500000</td>\n",
       "      <td>908.200012</td>\n",
       "      <td>894.402832</td>\n",
       "      <td>3898676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>06-04-2018</td>\n",
       "      <td>908.000000</td>\n",
       "      <td>918.500000</td>\n",
       "      <td>905.000000</td>\n",
       "      <td>911.000000</td>\n",
       "      <td>897.160339</td>\n",
       "      <td>4418462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>24-07-2019</td>\n",
       "      <td>1273.500000</td>\n",
       "      <td>1278.800049</td>\n",
       "      <td>1253.550049</td>\n",
       "      <td>1259.099976</td>\n",
       "      <td>1247.546387</td>\n",
       "      <td>6943982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>25-07-2019</td>\n",
       "      <td>1264.000000</td>\n",
       "      <td>1269.050049</td>\n",
       "      <td>1227.000000</td>\n",
       "      <td>1231.500000</td>\n",
       "      <td>1220.199707</td>\n",
       "      <td>9968545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>26-07-2019</td>\n",
       "      <td>1231.500000</td>\n",
       "      <td>1242.500000</td>\n",
       "      <td>1210.000000</td>\n",
       "      <td>1213.800049</td>\n",
       "      <td>1202.662231</td>\n",
       "      <td>9320481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>29-07-2019</td>\n",
       "      <td>1216.900024</td>\n",
       "      <td>1222.000000</td>\n",
       "      <td>1205.099976</td>\n",
       "      <td>1210.949951</td>\n",
       "      <td>1199.838257</td>\n",
       "      <td>8058035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>30-07-2019</td>\n",
       "      <td>1213.949951</td>\n",
       "      <td>1220.000000</td>\n",
       "      <td>1175.949951</td>\n",
       "      <td>1180.900024</td>\n",
       "      <td>1170.064087</td>\n",
       "      <td>9533344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>328 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date         Open         High          Low        Close  \\\n",
       "0    02-04-2018   893.000000   900.950012   886.500000   892.950012   \n",
       "1    03-04-2018   891.000000   901.700012   885.250000   899.549988   \n",
       "2    04-04-2018   904.700012   911.799988   892.049988   894.900024   \n",
       "3    05-04-2018   905.099976   910.000000   903.500000   908.200012   \n",
       "4    06-04-2018   908.000000   918.500000   905.000000   911.000000   \n",
       "..          ...          ...          ...          ...          ...   \n",
       "323  24-07-2019  1273.500000  1278.800049  1253.550049  1259.099976   \n",
       "324  25-07-2019  1264.000000  1269.050049  1227.000000  1231.500000   \n",
       "325  26-07-2019  1231.500000  1242.500000  1210.000000  1213.800049   \n",
       "326  29-07-2019  1216.900024  1222.000000  1205.099976  1210.949951   \n",
       "327  30-07-2019  1213.949951  1220.000000  1175.949951  1180.900024   \n",
       "\n",
       "       Adj Close   Volume  \n",
       "0     879.384521  5712065  \n",
       "1     885.884277  6364728  \n",
       "2     881.304932  6498407  \n",
       "3     894.402832  3898676  \n",
       "4     897.160339  4418462  \n",
       "..           ...      ...  \n",
       "323  1247.546387  6943982  \n",
       "324  1220.199707  9968545  \n",
       "325  1202.662231  9320481  \n",
       "326  1199.838257  8058035  \n",
       "327  1170.064087  9533344  \n",
       "\n",
       "[328 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join('Images', 'Training')\n",
    "validation_dir = os.path.join('Images', 'Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e4bAyHXfK7_4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training images: 1732\n",
      "Total validation images: 308\n"
     ]
    }
   ],
   "source": [
    "train_buy_dir = os.path.join(train_dir, 'Buy')  # directory with our training  Buy pictures\n",
    "train_hold_dir = os.path.join(train_dir, 'Hold')  # directory with our training Hold pictures\n",
    "train_sell_dir = os.path.join(train_dir, 'Sell')  # directory with our training Sell pictures\n",
    "validation_buy_dir = os.path.join(validation_dir, 'Buy')  # directory with our validation Buy pictures\n",
    "validation_hold_dir = os.path.join(validation_dir, 'Hold')  # directory with our validation Hold pictures\n",
    "validation_sell_dir = os.path.join(validation_dir, 'Sell')  # directory with our validation Sell pictures\n",
    "\n",
    "num_buy_tr = len(os.listdir(train_buy_dir))\n",
    "num_hold_tr = len(os.listdir(train_hold_dir))\n",
    "num_sell_tr = len(os.listdir(train_sell_dir))\n",
    "\n",
    "num_buy_val = len(os.listdir(validation_buy_dir))\n",
    "num_hold_val = len(os.listdir(validation_hold_dir))\n",
    "num_sell_val = len(os.listdir(validation_sell_dir))\n",
    "\n",
    "total_train = num_buy_tr + num_hold_tr + num_sell_tr\n",
    "total_val = num_buy_val + num_hold_val + num_sell_val\n",
    "\n",
    "\n",
    "\n",
    "print(\"Total training images:\", total_train)\n",
    "print(\"Total validation images:\", total_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "60obDDFzLEbR"
   },
   "outputs": [],
   "source": [
    "# initializing parameters for further use\n",
    "batch_size = 32\n",
    "epochs = 100\n",
    "IMG_HEIGHT = 12\n",
    "IMG_WIDTH = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zmDmet36NHRF"
   },
   "source": [
    "# ***Data Augmentation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZWN3IhiSLIzl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1732 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "image_gen_train = ImageDataGenerator(\n",
    "    rescale=1./255,featurewise_center=True,\n",
    "    \n",
    "    width_shift_range=0.1,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='reflect',\n",
    "    )\n",
    "\n",
    "validation_image_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data_gen =image_gen_train.flow_from_directory(batch_size=batch_size,\n",
    "                                                     directory=train_dir,\n",
    "                                                     shuffle=True,color_mode=\"rgb\",\n",
    "                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                     class_mode='sparse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JjIadl8kLX1r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 308 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,\n",
    "                                                              directory=validation_dir,color_mode=\"rgb\",\n",
    "                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                              class_mode='sparse')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aJMqn0huM_XL"
   },
   "source": [
    "# ***Model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j2Xp6oLLYv4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 10, 13, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 8, 11, 64)         18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1280)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               163968    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 387       \n",
      "=================================================================\n",
      "Total params: 183,747\n",
      "Trainable params: 183,747\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras import regularizers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=(12,15,3)),\n",
    "        layers.Conv2D(32,kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.Conv2D(64,kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Dropout(0.25,seed=0),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.compile(optimizer='rmsprop',\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LROqBcGxM2Dx"
   },
   "source": [
    "# ***Computational Performance***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lc7sjo-JLh6V"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rialk\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rialk\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py:4930: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  '\"`sparse_categorical_crossentropy` received `from_logits=True`, but '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 7s 68ms/step - loss: 1.0483 - accuracy: 0.4740 - val_loss: 1.0756 - val_accuracy: 0.4132\n",
      "Epoch 2/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 1.0152 - accuracy: 0.4929 - val_loss: 1.0495 - val_accuracy: 0.4688\n",
      "Epoch 3/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 1.0042 - accuracy: 0.5023 - val_loss: 1.0998 - val_accuracy: 0.2847\n",
      "Epoch 4/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 1.0012 - accuracy: 0.5206 - val_loss: 1.0808 - val_accuracy: 0.3090\n",
      "Epoch 5/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9919 - accuracy: 0.5259 - val_loss: 1.1132 - val_accuracy: 0.2986\n",
      "Epoch 6/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9865 - accuracy: 0.5335 - val_loss: 1.2201 - val_accuracy: 0.2778\n",
      "Epoch 7/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9783 - accuracy: 0.5365 - val_loss: 1.2045 - val_accuracy: 0.3021\n",
      "Epoch 8/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9688 - accuracy: 0.5480 - val_loss: 1.2356 - val_accuracy: 0.2882\n",
      "Epoch 9/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9704 - accuracy: 0.5453 - val_loss: 1.2346 - val_accuracy: 0.2986\n",
      "Epoch 10/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9700 - accuracy: 0.5506 - val_loss: 1.2757 - val_accuracy: 0.2743\n",
      "Epoch 11/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9699 - accuracy: 0.5618 - val_loss: 1.2358 - val_accuracy: 0.3125\n",
      "Epoch 12/100\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.9604 - accuracy: 0.5641 - val_loss: 1.2517 - val_accuracy: 0.3021\n",
      "Epoch 13/100\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.9536 - accuracy: 0.5482 - val_loss: 1.2797 - val_accuracy: 0.3125\n",
      "Epoch 14/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9611 - accuracy: 0.5559 - val_loss: 1.2858 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9647 - accuracy: 0.5529 - val_loss: 1.2518 - val_accuracy: 0.3264\n",
      "Epoch 16/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9653 - accuracy: 0.5535 - val_loss: 1.4788 - val_accuracy: 0.2812\n",
      "Epoch 17/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9568 - accuracy: 0.5529 - val_loss: 1.4299 - val_accuracy: 0.2951\n",
      "Epoch 18/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9551 - accuracy: 0.5500 - val_loss: 1.2187 - val_accuracy: 0.3750\n",
      "Epoch 19/100\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.9572 - accuracy: 0.5624 - val_loss: 1.3599 - val_accuracy: 0.3889\n",
      "Epoch 20/100\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 0.9445 - accuracy: 0.5559 - val_loss: 1.5465 - val_accuracy: 0.2743\n",
      "Epoch 21/100\n",
      "54/54 [==============================] - 3s 61ms/step - loss: 0.9510 - accuracy: 0.5629 - val_loss: 1.7023 - val_accuracy: 0.3611\n",
      "Epoch 22/100\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.9529 - accuracy: 0.5624 - val_loss: 1.2824 - val_accuracy: 0.4167\n",
      "Epoch 23/100\n",
      "54/54 [==============================] - 4s 65ms/step - loss: 0.9522 - accuracy: 0.5671 - val_loss: 1.7301 - val_accuracy: 0.3194\n",
      "Epoch 24/100\n",
      "54/54 [==============================] - 4s 64ms/step - loss: 0.9471 - accuracy: 0.5665 - val_loss: 1.1691 - val_accuracy: 0.4479\n",
      "Epoch 25/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9369 - accuracy: 0.5718 - val_loss: 1.2151 - val_accuracy: 0.4028\n",
      "Epoch 26/100\n",
      "54/54 [==============================] - 3s 57ms/step - loss: 0.9433 - accuracy: 0.5706 - val_loss: 1.1243 - val_accuracy: 0.4340\n",
      "Epoch 27/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9480 - accuracy: 0.5659 - val_loss: 1.3402 - val_accuracy: 0.4201\n",
      "Epoch 28/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9408 - accuracy: 0.5700 - val_loss: 1.2559 - val_accuracy: 0.4306\n",
      "Epoch 29/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9431 - accuracy: 0.5712 - val_loss: 1.2624 - val_accuracy: 0.4236\n",
      "Epoch 30/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9449 - accuracy: 0.5712 - val_loss: 1.3581 - val_accuracy: 0.4167\n",
      "Epoch 31/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9500 - accuracy: 0.5635 - val_loss: 1.4185 - val_accuracy: 0.4201\n",
      "Epoch 32/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9474 - accuracy: 0.5518 - val_loss: 1.3121 - val_accuracy: 0.3958\n",
      "Epoch 33/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9444 - accuracy: 0.5753 - val_loss: 1.1437 - val_accuracy: 0.4375\n",
      "Epoch 34/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9344 - accuracy: 0.5782 - val_loss: 1.5804 - val_accuracy: 0.4167\n",
      "Epoch 35/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9499 - accuracy: 0.5529 - val_loss: 1.3228 - val_accuracy: 0.4271\n",
      "Epoch 36/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9443 - accuracy: 0.5718 - val_loss: 1.3704 - val_accuracy: 0.4375\n",
      "Epoch 37/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9381 - accuracy: 0.5771 - val_loss: 1.7312 - val_accuracy: 0.4201\n",
      "Epoch 38/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9410 - accuracy: 0.5794 - val_loss: 1.2889 - val_accuracy: 0.4236\n",
      "Epoch 39/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9320 - accuracy: 0.5694 - val_loss: 1.4428 - val_accuracy: 0.4410\n",
      "Epoch 40/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9411 - accuracy: 0.5712 - val_loss: 1.6140 - val_accuracy: 0.4236\n",
      "Epoch 41/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9387 - accuracy: 0.5729 - val_loss: 1.0477 - val_accuracy: 0.4896\n",
      "Epoch 42/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9337 - accuracy: 0.5776 - val_loss: 1.2524 - val_accuracy: 0.4271\n",
      "Epoch 43/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9382 - accuracy: 0.5758 - val_loss: 1.4897 - val_accuracy: 0.4306\n",
      "Epoch 44/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9369 - accuracy: 0.5835 - val_loss: 1.2311 - val_accuracy: 0.4132\n",
      "Epoch 45/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9425 - accuracy: 0.5706 - val_loss: 1.3766 - val_accuracy: 0.4167\n",
      "Epoch 46/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9345 - accuracy: 0.5747 - val_loss: 1.7188 - val_accuracy: 0.3611\n",
      "Epoch 47/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9272 - accuracy: 0.5794 - val_loss: 1.3292 - val_accuracy: 0.3785\n",
      "Epoch 48/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9263 - accuracy: 0.5747 - val_loss: 1.1985 - val_accuracy: 0.3993\n",
      "Epoch 49/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9343 - accuracy: 0.5800 - val_loss: 1.2238 - val_accuracy: 0.4479\n",
      "Epoch 50/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9340 - accuracy: 0.5841 - val_loss: 1.1897 - val_accuracy: 0.4340\n",
      "Epoch 51/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9274 - accuracy: 0.5712 - val_loss: 1.2065 - val_accuracy: 0.4444\n",
      "Epoch 52/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9373 - accuracy: 0.5788 - val_loss: 1.2800 - val_accuracy: 0.4271\n",
      "Epoch 53/100\n",
      "54/54 [==============================] - 3s 52ms/step - loss: 0.9268 - accuracy: 0.5847 - val_loss: 1.2158 - val_accuracy: 0.3924\n",
      "Epoch 54/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9261 - accuracy: 0.5876 - val_loss: 1.2495 - val_accuracy: 0.4028\n",
      "Epoch 55/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9323 - accuracy: 0.5794 - val_loss: 1.1351 - val_accuracy: 0.4653\n",
      "Epoch 56/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9367 - accuracy: 0.5718 - val_loss: 1.3125 - val_accuracy: 0.4236\n",
      "Epoch 57/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9276 - accuracy: 0.5753 - val_loss: 1.4596 - val_accuracy: 0.3854\n",
      "Epoch 58/100\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.9344 - accuracy: 0.5729 - val_loss: 1.4234 - val_accuracy: 0.4306\n",
      "Epoch 59/100\n",
      "54/54 [==============================] - 4s 66ms/step - loss: 0.9305 - accuracy: 0.5882 - val_loss: 1.2646 - val_accuracy: 0.4236\n",
      "Epoch 60/100\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 0.9235 - accuracy: 0.5865 - val_loss: 1.4757 - val_accuracy: 0.4236\n",
      "Epoch 61/100\n",
      "54/54 [==============================] - 4s 69ms/step - loss: 0.9316 - accuracy: 0.5876 - val_loss: 1.1067 - val_accuracy: 0.4896\n",
      "Epoch 62/100\n",
      "54/54 [==============================] - 4s 68ms/step - loss: 0.9243 - accuracy: 0.5894 - val_loss: 1.3871 - val_accuracy: 0.4306\n",
      "Epoch 63/100\n",
      "54/54 [==============================] - 4s 65ms/step - loss: 0.9269 - accuracy: 0.5876 - val_loss: 1.2569 - val_accuracy: 0.4549\n",
      "Epoch 64/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9288 - accuracy: 0.5894 - val_loss: 1.0734 - val_accuracy: 0.4826\n",
      "Epoch 65/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9205 - accuracy: 0.5841 - val_loss: 1.3921 - val_accuracy: 0.4514\n",
      "Epoch 66/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9242 - accuracy: 0.5824 - val_loss: 1.3704 - val_accuracy: 0.4375\n",
      "Epoch 67/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9306 - accuracy: 0.5712 - val_loss: 1.1350 - val_accuracy: 0.4861\n",
      "Epoch 68/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9189 - accuracy: 0.5982 - val_loss: 1.3765 - val_accuracy: 0.4514\n",
      "Epoch 69/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9249 - accuracy: 0.6000 - val_loss: 1.5400 - val_accuracy: 0.4375\n",
      "Epoch 70/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9306 - accuracy: 0.5882 - val_loss: 1.4775 - val_accuracy: 0.4444\n",
      "Epoch 71/100\n",
      "54/54 [==============================] - 3s 56ms/step - loss: 0.9246 - accuracy: 0.5800 - val_loss: 1.2828 - val_accuracy: 0.4479\n",
      "Epoch 72/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9198 - accuracy: 0.5841 - val_loss: 1.2661 - val_accuracy: 0.4583\n",
      "Epoch 73/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9195 - accuracy: 0.5771 - val_loss: 1.1990 - val_accuracy: 0.4618\n",
      "Epoch 74/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9232 - accuracy: 0.5776 - val_loss: 1.1070 - val_accuracy: 0.4896\n",
      "Epoch 75/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9341 - accuracy: 0.5812 - val_loss: 1.2201 - val_accuracy: 0.4653\n",
      "Epoch 76/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9287 - accuracy: 0.5865 - val_loss: 1.4744 - val_accuracy: 0.4410\n",
      "Epoch 77/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9153 - accuracy: 0.5918 - val_loss: 1.2177 - val_accuracy: 0.4861\n",
      "Epoch 78/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9215 - accuracy: 0.5988 - val_loss: 1.1520 - val_accuracy: 0.4792\n",
      "Epoch 79/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9225 - accuracy: 0.6012 - val_loss: 1.0584 - val_accuracy: 0.4514\n",
      "Epoch 80/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9229 - accuracy: 0.5859 - val_loss: 1.3489 - val_accuracy: 0.4479\n",
      "Epoch 81/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9291 - accuracy: 0.5882 - val_loss: 1.1532 - val_accuracy: 0.4688\n",
      "Epoch 82/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9155 - accuracy: 0.5929 - val_loss: 1.5956 - val_accuracy: 0.4236\n",
      "Epoch 83/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9185 - accuracy: 0.5824 - val_loss: 1.3252 - val_accuracy: 0.4479\n",
      "Epoch 84/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9213 - accuracy: 0.5800 - val_loss: 1.4716 - val_accuracy: 0.4201\n",
      "Epoch 85/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9269 - accuracy: 0.5882 - val_loss: 1.1072 - val_accuracy: 0.4618\n",
      "Epoch 86/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9215 - accuracy: 0.5865 - val_loss: 1.1984 - val_accuracy: 0.4896\n",
      "Epoch 87/100\n",
      "54/54 [==============================] - 3s 53ms/step - loss: 0.9228 - accuracy: 0.5841 - val_loss: 1.4406 - val_accuracy: 0.4271\n",
      "Epoch 88/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9163 - accuracy: 0.5924 - val_loss: 1.7213 - val_accuracy: 0.4201\n",
      "Epoch 89/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9216 - accuracy: 0.5735 - val_loss: 1.4467 - val_accuracy: 0.4201\n",
      "Epoch 90/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9188 - accuracy: 0.5900 - val_loss: 1.5790 - val_accuracy: 0.3924\n",
      "Epoch 91/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9172 - accuracy: 0.5941 - val_loss: 1.4953 - val_accuracy: 0.4583\n",
      "Epoch 92/100\n",
      "54/54 [==============================] - 3s 58ms/step - loss: 0.9193 - accuracy: 0.5871 - val_loss: 1.8231 - val_accuracy: 0.3958\n",
      "Epoch 93/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9177 - accuracy: 0.5976 - val_loss: 1.3927 - val_accuracy: 0.4514\n",
      "Epoch 94/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9250 - accuracy: 0.5824 - val_loss: 1.3333 - val_accuracy: 0.4444\n",
      "Epoch 95/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9232 - accuracy: 0.5847 - val_loss: 1.2627 - val_accuracy: 0.4514\n",
      "Epoch 96/100\n",
      "54/54 [==============================] - 3s 54ms/step - loss: 0.9270 - accuracy: 0.5894 - val_loss: 1.2166 - val_accuracy: 0.4688\n",
      "Epoch 97/100\n",
      "54/54 [==============================] - 3s 55ms/step - loss: 0.9253 - accuracy: 0.5782 - val_loss: 1.3713 - val_accuracy: 0.4549\n",
      "Epoch 98/100\n",
      "54/54 [==============================] - 3s 59ms/step - loss: 0.9170 - accuracy: 0.5876 - val_loss: 1.1916 - val_accuracy: 0.4931\n",
      "Epoch 99/100\n",
      "54/54 [==============================] - 3s 61ms/step - loss: 0.9204 - accuracy: 0.5965 - val_loss: 1.2321 - val_accuracy: 0.4722\n",
      "Epoch 100/100\n",
      "54/54 [==============================] - 3s 63ms/step - loss: 0.9130 - accuracy: 0.5918 - val_loss: 1.2863 - val_accuracy: 0.4722\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data_gen,\n",
    "    steps_per_epoch=total_train // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_data_gen,\n",
    "    validation_steps=total_val // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 328 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "image_gen_test = ImageDataGenerator(rescale=1./255)\n",
    "test_data_gen = image_gen_test.flow_from_directory(batch_size=batch_size,\n",
    "                                                 directory='Images/Testing',\n",
    "                                                 target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
    "                                                 class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-xaUMCyL3M-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 11 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4675324559211731"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_loss,val_acc =model.evaluate(val_data_gen,steps=len(test_data_gen),verbose=0)\n",
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4146341383457184"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss,test_acc = model.evaluate(test_data_gen,steps=len(test_data_gen),verbose=0)\n",
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MSqmJomJLi3P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f91867de08>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'], label='acc')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0.2, 1])\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vn5D5lYTMZj5"
   },
   "source": [
    "## ***Financial Evaluation***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yIM59JdpMKka"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 1, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 2, 2, 2, 2, 2, 2, 2, 0, 1, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 1, 0, 2, 2, 2, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 0, 0, 0, 0, 0, 2, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 0, 2, 0, 0, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "labels_pred=[]\n",
    "\n",
    "PATH = os.getcwd()\n",
    "data_path =  'Images/Testing'\n",
    "data_dir_list = os.listdir(data_path)\n",
    "\n",
    "img_data_list=[]\n",
    "for dataset in data_dir_list:\n",
    "    img_list=os.listdir(data_path+'/'+ dataset)\n",
    "    for img in img_list:\n",
    "        img_path = data_path + '/'+ dataset + '/'+ img\n",
    "        img = keras.preprocessing.image.load_img(img_path, target_size=(IMG_HEIGHT, IMG_WIDTH))\n",
    "        test_img = image.img_to_array(img)/255\n",
    "        test_img=np.array(test_img)\n",
    "        img_array = tf.expand_dims(test_img, 0)  # Create batch axis\n",
    "        labels_pred.append(np.argmax(model.predict(img_array),axis=1)[0])\n",
    "        \n",
    "print(labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZcEyjDDLMQsg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date : 28, cost : -974.2216189999999,buy_c:1,price:974.2216189999999 Buy\n",
      "date : 58, cost :22.896728000000167,buy_c:0,price:997.1183470000001 Sell\n",
      "date : 61, cost : -934.0906379999999,buy_c:1,price:956.9873660000001 Buy\n",
      "date : 68, cost :34.4893790000001,buy_c:0,price:968.580017 Sell\n",
      "date : 72, cost : -1037.928956,buy_c:1,price:1072.418335 Buy\n",
      "date : 100, cost :219.8724360000001,buy_c:0,price:1257.801392 Sell\n",
      "date : 107, cost : -997.998902,buy_c:1,price:1217.8713380000002 Buy\n",
      "date : 114, cost :243.00817800000004,buy_c:0,price:1241.00708 Sell\n",
      "date : 115, cost : -998.642945,buy_c:1,price:1241.651123 Buy\n",
      "date : 123, cost :243.60266000000001,buy_c:0,price:1242.245605 Sell\n",
      "date : 125, cost : -976.795167,buy_c:1,price:1220.397827 Buy\n",
      "date : 200, cost :249.5476060000001,buy_c:0,price:1226.342773 Sell\n",
      "date : 208, cost : -966.342165,buy_c:1,price:1215.889771 Buy\n",
      "date : 213, cost :312.21716100000003,buy_c:0,price:1278.559326 Sell\n",
      "date : 214, cost : -953.7585469999999,buy_c:1,price:1265.975708 Buy\n",
      "date : 233, cost :338.374998,buy_c:0,price:1292.133545 Sell\n",
      "date : 237, cost : -971.1475849999999,buy_c:1,price:1309.522583 Buy\n",
      "date : 246, cost :407.9307839999999,buy_c:0,price:1379.0783689999998 Sell\n",
      "date : 272, cost : -812.813967,buy_c:1,price:1220.744751 Buy\n",
      "date : 273, cost :436.070066,buy_c:0,price:1248.884033 Sell\n",
      "date : 274, cost : -809.2966329999999,buy_c:1,price:1245.366699 Buy\n",
      "date : 277, cost :504.4368880000002,buy_c:0,price:1313.733521 Sell\n",
      "date : 286, cost : -813.5076919999999,buy_c:1,price:1317.94458 Buy\n",
      "date : 287, cost :534.2110580000001,buy_c:0,price:1347.71875 Sell\n",
      "date : 288, cost : -805.0362559999999,buy_c:1,price:1339.247314 Buy\n",
      "-805.0362559999999\n",
      "13\n",
      "12\n",
      "win: 12\n",
      "loss: 0\n"
     ]
    }
   ],
   "source": [
    "df['prediction']=labels_pred\n",
    "icost=[]\n",
    "buy_l=[]\n",
    "cost=0\n",
    "buy_c=0\n",
    "buy=0\n",
    "sell=0\n",
    "win=0\n",
    "loss=0\n",
    "\n",
    "for i in df.index:\n",
    "    if(df['prediction'][i]==0):\n",
    "        if(buy_c<=0):\n",
    "            buy_c=buy_c+1\n",
    "            buy=buy+1\n",
    "            cost=cost - df['Adj Close'][i]\n",
    "            x=df['Adj Close'][i]\n",
    "            #print(cost)\n",
    "            buy_l.append(x)\n",
    "            print(\"date : {}, cost : {},buy_c:{},price:{}\".format(i, cost,buy_c,x),'Buy')\n",
    "    if(df['prediction'][i]==2):\n",
    "        y=df['Adj Close'][i]\n",
    "        if(buy_c>=1):\n",
    "            if(y-x>0):\n",
    "                buy_c=buy_c-1\n",
    "                sell=sell+1\n",
    "                cost=cost+df['Adj Close'][i]\n",
    "                print(\"date : {}, cost :{},buy_c:{},price:{}\".format(i, cost,buy_c,y),\"Sell\")\n",
    "                if((buy>0) & (sell>0)):\n",
    "                    if(y-x<0):\n",
    "                        loss=loss+1\n",
    "                    if(y-x>0):\n",
    "                        win=win+1\n",
    "                    icost.append(y-x)\n",
    "    if(df['prediction'][i]==1):\n",
    "        continue\n",
    " \n",
    "print(cost)\n",
    "#print((cost-icost)/icost)\n",
    "print(buy)\n",
    "print(sell)\n",
    "print(\"win:\",win)\n",
    "print('loss:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
